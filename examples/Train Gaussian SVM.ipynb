{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the simulated data used in the DeepLIFT paper. The the pwms for the GATA motif and TAL motif (GATA_disc1 and TAL1_known1 from http://compbio.mit.edu/encode-motifs/) are used to generate motifs which are inserted into a random background. Sequences containing at least one GATA motif are a 1 for task 1, 0 otherwise. Sequences containing at least one TAL motif are a 1 for task 2, 0 otherwise. Sequences containing both a TAL and a GATA motif are a 1 for task 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File sequences.simdata.gz exists already\r\n"
     ]
    }
   ],
   "source": [
    "!./grab_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import simdna\n",
    "except ImportError, e:\n",
    "    print(\"installing simdna package\")\n",
    "    !pip install -e \"git://github.com/kundajelab/simdna.git@0.4.0#egg=simdna\"\n",
    "    print(\"\\n******************************************************************************\")\n",
    "    print(\"RESTART THE JUPYTER KERNEL TO PICK UP ON THE INSTALLATION!!!\")\n",
    "    print(\"******************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import simdna.synthetic as synthetic\n",
    "import gzip\n",
    "\n",
    "data_filename = \"sequences.simdata.gz\"\n",
    "data = synthetic.read_simdata_file(data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the sequence data into a 3d array, where the last axis (\"channel\" axis) is the ACGT axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    #theano dim ordering, uses row axis for one-hot\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1): \n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1\n",
    "            \n",
    "onehot_data = np.array([one_hot_encode_along_channel_axis(seq) for seq in data.sequences])\n",
    "print(onehot_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the gapped kmer embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute the embeddings using the GPU to scan for matches to the gapped kmers, allowing for some numbed of mismatches. First, we will prepare the function that is going to do our scanning on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING:theano.sandbox.cuda:The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GT 750M (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import ssvmimp\n",
    "import ssvmimp.train\n",
    "\n",
    "max_mismatches=0\n",
    "\n",
    "filters, string_reps, embedding_func = ssvmimp.train.get_gapped_kmer_embedding_filters_and_func(\n",
    "                                kmer_len=6, alphabet=['A','C','G','T'],\n",
    "                                num_gaps=1, max_mismatches=max_mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'string_reps' stores string representations of the filters, as shown below (gaps are indicated with whitespace):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filters: 5120\n",
      "First ten filters:\n",
      "AAAAA \n",
      "AAAAC \n",
      "AAAAG \n",
      "AAAAT \n",
      "AAACA \n",
      "AAACC \n",
      "AAACG \n",
      "AAACT \n",
      "AAAGA \n",
      "AAAGC \n",
      "Last ten filters:\n",
      "T TTCG\n",
      "T TTCT\n",
      "T TTGA\n",
      "T TTGC\n",
      "T TTGG\n",
      "T TTGT\n",
      "T TTTA\n",
      "T TTTC\n",
      "T TTTG\n",
      "T TTTT\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of filters:\",len(string_reps))\n",
    "print(\"First ten filters:\")\n",
    "print(\"\\n\".join(string_reps[:10]))\n",
    "print(\"Last ten filters:\")\n",
    "print(\"\\n\".join(string_reps[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compute the embeddings, which are the sum of the number of matches to each filter per sequence, accounting for the desired number of mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "Done 1500\n",
      "Done 2000\n",
      "Done 2500\n",
      "Done 3000\n",
      "Done 3500\n",
      "Done 4000\n",
      "Done 4500\n",
      "Done 5000\n",
      "Done 5500\n",
      "Done 6000\n",
      "Done 6500\n",
      "Done 7000\n",
      "Done 7500\n",
      "Shape of the embeddings matrix: (8000, 5120)\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedding_func(onehot=onehot_data, batch_size=20, progress_update=500)\n",
    "print(\"Shape of the embeddings matrix:\",embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit features to gkmers that are statistically overrepresented in the positive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_num = 6000 #6000 examples will be used in the training set\n",
    "train_embeddings = embeddings[:train_set_num]\n",
    "kmer_counts_positives = np.sum(train_embeddings[data.labels[:train_set_num,0]==1]>0,axis=0)\n",
    "kmer_counts_negatives = np.sum(train_embeddings[data.labels[:train_set_num,0]==0]>0,axis=0)\n",
    "total_positives = np.sum(data.labels[:train_set_num,0])\n",
    "total_negatives = np.sum(1-data.labels[:train_set_num,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n"
     ]
    }
   ],
   "source": [
    "import ssvmimp.stats.stats\n",
    "reload(ssvmimp.stats.stats)\n",
    "\n",
    "significant_kmer_indices = []\n",
    "for i,(kmer_count_pos, kmer_count_neg) in enumerate(zip(kmer_counts_positives, kmer_counts_negatives)):\n",
    "    total = total_positives + total_negatives\n",
    "    special = total_positives\n",
    "    picked = kmer_count_pos+kmer_count_neg\n",
    "    specialPicked = kmer_count_pos\n",
    "    result = ssvmimp.stats.stats.proportionTest(\n",
    "                total=total, special=special,\n",
    "                picked=picked, specialPicked=specialPicked)\n",
    "    if (result.pval < 0.05):\n",
    "        significant_kmer_indices.append(i)\n",
    "\n",
    "print(len(significant_kmer_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the embeddings so that the rows have unit magnitude. Only consider overrepresented kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized embeddings shape: (8000, 530)\n"
     ]
    }
   ],
   "source": [
    "normalized_embeddings = (embeddings[:,significant_kmer_indices]/\n",
    "                         np.linalg.norm(embeddings[:,significant_kmer_indices], axis=1)[:,None])\n",
    "print(\"Normalized embeddings shape:\",normalized_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVMs given the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training linear SVM for t0\n",
      "Linear SVM accuracy for task 0 : 0.857\n"
     ]
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "import sys\n",
    "\n",
    "print(\"Training linear SVM for t0\")\n",
    "sys.stdout.flush()\n",
    "t0_linear_classifier = sklearn.svm.LinearSVC().fit(X=normalized_embeddings[:train_set_num], y=data.labels[:train_set_num,0])\n",
    "preds = t0_linear_classifier.predict(normalized_embeddings[train_set_num:])\n",
    "print(\"Linear SVM accuracy for task\",0,\":\",np.sum(data.labels[train_set_num:,0] == preds)/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian SVM test accuracy for task 0 : 0.9485\n",
      "Gaussian SVM train accuracy for task 0 : 0.9721666666666666\n",
      "Number of support vectors: [1213  959]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "t0_gaussian_classifier = sklearn.svm.SVC(C=1.0, kernel=\"rbf\", gamma=1.0).fit(\n",
    "                X=normalized_embeddings[:train_set_num],\n",
    "                y=data.labels[:train_set_num,0])\n",
    "preds = t0_gaussian_classifier.predict(normalized_embeddings[train_set_num:])\n",
    "print(\"Gaussian SVM test accuracy for task\",0,\":\",np.sum(data.labels[train_set_num:,0] == preds)/len(preds))\n",
    "train_preds = t0_gaussian_classifier.predict(normalized_embeddings[:train_set_num])\n",
    "print(\"Gaussian SVM train accuracy for task\",0,\":\",np.sum(data.labels[:train_set_num,0] == train_preds)/len(train_preds))\n",
    "print(\"Number of support vectors:\",t0_gaussian_classifier.n_support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
