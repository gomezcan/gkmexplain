{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File sequences.simdata.gz exists already\r\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "!./grab_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import simdna\n",
    "except ImportError, e:\n",
    "    print(\"installing simdna package\")\n",
    "    !pip install -e \"git://github.com/kundajelab/simdna.git@0.4.0#egg=simdna\"\n",
    "    print(\"\\n******************************************************************************\")\n",
    "    print(\"RESTART THE JUPYTER KERNEL TO PICK UP ON THE INSTALLATION!!!\")\n",
    "    print(\"******************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import simdna.synthetic as synthetic\n",
    "reload(synthetic)\n",
    "reload(synthetic.core)\n",
    "import gzip\n",
    "data_filename = \"sequences.simdata.gz\"\n",
    "data = synthetic.read_simdata_file(data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the sequence data into a 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    #theano dim ordering, uses row axis for one-hot\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1): \n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1\n",
    "            \n",
    "onehot_data = np.array([one_hot_encode_along_channel_axis(seq) for seq in data.sequences])\n",
    "print(onehot_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computed the gapped kmer embeddings; first, obtain a function that will compute the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ssvmimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ssvmimp.train\n",
    "reload(ssvmimp.train)\n",
    "\n",
    "num_mismatches=1\n",
    "\n",
    "string_reps, embedding_func = ssvmimp.train.get_gapped_kmer_embedding_filters_and_func(\n",
    "                                kmer_len=6, alphabet=['A','C','G','T'],\n",
    "                                num_gaps=2, num_mismatches=num_mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'string_reps' stores string representations of the filters. Positions are separated by commas. The number represents the letter (0=A, 1=C, 2=G, 3=T)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560\n",
      "First ten filters:\n",
      "AAAA  \n",
      "AAAC  \n",
      "AAAG  \n",
      "AAAT  \n",
      "AACA  \n",
      "AACC  \n",
      "AACG  \n",
      "AACT  \n",
      "AAGA  \n",
      "AAGC  \n",
      "Last ten filters:\n",
      "T  TCG\n",
      "T  TCT\n",
      "T  TGA\n",
      "T  TGC\n",
      "T  TGG\n",
      "T  TGT\n",
      "T  TTA\n",
      "T  TTC\n",
      "T  TTG\n",
      "T  TTT\n"
     ]
    }
   ],
   "source": [
    "print(len(string_reps))\n",
    "print(\"First ten filters:\")\n",
    "print(\"\\n\".join(string_reps[:10]))\n",
    "print(\"Last ten filters:\")\n",
    "print(\"\\n\".join(string_reps[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computed the embeddings, which are the sum of the number of matches to each filter per sequence, accounting for the desired number of mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 500\n",
      "Done 1000\n",
      "Done 1500\n",
      "Done 2000\n",
      "Done 2500\n",
      "Done 3000\n",
      "Done 3500\n",
      "Done 4000\n",
      "Done 4500\n",
      "Done 5000\n",
      "Done 5500\n",
      "Done 6000\n",
      "Done 6500\n",
      "Done 7000\n",
      "Done 7500\n",
      "(8000, 2560)\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedding_func(onehot=onehot_data, batch_size=20, progress_update=500)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier on task 1 (\"GATA present\") and task 2 (\"TAL present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training t1\n",
      "Training t2\n"
     ]
    }
   ],
   "source": [
    "import sklearn.svm\n",
    "import sys\n",
    "\n",
    "train_set_num = 6000 #6000 examples will be used in the training set\n",
    "print(\"Training t1\")\n",
    "sys.stdout.flush()\n",
    "t1_classifier = sklearn.svm.LinearSVC().fit(X=embeddings[:train_set_num], y=data.labels[:train_set_num,1])\n",
    "print(\"Training t2\")\n",
    "sys.stdout.flush()\n",
    "t2_classifier = sklearn.svm.LinearSVC().fit(X=embeddings[:train_set_num], y=data.labels[:train_set_num,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8735\n",
      "0.9235\n"
     ]
    }
   ],
   "source": [
    "#check prediction accuracy on testing set (6000:8000)\n",
    "for classifier, task in [(t1_classifier,1), (t2_classifier,2)]:\n",
    "    preds = classifier.predict(embeddings[train_set_num:])\n",
    "    print(np.sum(data.labels[train_set_num:,task] == preds)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the top-ranked filters for the two tasks by eye. coef_[0] stores the weights on the filters. The GATA PWM used was GATA_disc1 and the TAL motif used was TAL1_known1 from here: http://compbio.mit.edu/encode-motifs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 filters:\n",
      "[(0.072067056160371512, 'C A TA'), (0.069113433440973732, 'GCT A '), (0.067823727133263609, 'T GAT '), (0.067592827570667258, 'G TCA '), (0.067471113890326895, 'G T AT'), (0.064120598074550811, 'TAT  G'), (0.062947203147330932, 'G TGA '), (0.058946593636511939, 'G TC G'), (0.058413859538917604, 'GC  AG'), (0.057370484628632257, 'TA AA ')]\n",
      "t2 filters:\n",
      "[(0.061417155777389619, 'C T TG'), (0.054530675145669651, 'C G GG'), (0.053834522908509777, 'AGTT  '), (0.051887418943053785, 'CA C G'), (0.049335179785569727, 'AT CT '), (0.048619322668626619, 'A CTG '), (0.047997753788824607, 'C GG G'), (0.047607954786425488, 'AA  AA'), (0.046646509260457297, 'TAT  T'), (0.045815000471540031, 'G AAA ')]\n"
     ]
    }
   ],
   "source": [
    "#get the top ranked filters for t1\n",
    "print(\"t1 filters:\")\n",
    "assert len(string_reps)==len(t1_classifier.coef_[0])\n",
    "t1_sorted_filters = sorted(zip(t1_classifier.coef_[0], string_reps), key=lambda x: -x[0])\n",
    "print(t1_sorted_filters[:10])\n",
    "\n",
    "print(\"t2 filters:\")\n",
    "assert len(string_reps)==len(t2_classifier.coef_[0])\n",
    "t2_sorted_filters = sorted(zip(t2_classifier.coef_[0], string_reps), key=lambda x: -x[0])\n",
    "print(t2_sorted_filters[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we will look at the scores for the GATAAG kmer (the GATA motif) and the CAGATG kmer (the TAL motif) for task 0 and task 1. First, we define functions to help us look at the total score for a kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def get_filter_matches(kmer_string, filter_strings, num_mismatches):\n",
    "    matching_filters = []\n",
    "    for filter_string in filter_strings:\n",
    "        match = True\n",
    "        mismatches_so_far = 0\n",
    "        for kmer_letter, filter_letter in zip(kmer_string, filter_string):\n",
    "            if (filter_letter!=\" \" and kmer_letter!=filter_letter):\n",
    "                mismatches_so_far += 1\n",
    "                if mismatches_so_far > num_mismatches:\n",
    "                    match=False\n",
    "                    break\n",
    "        if (match):\n",
    "            matching_filters.append(filter_string)\n",
    "    return matching_filters\n",
    "\n",
    "def get_total_kmer_score(kmer_string, filter_to_score, num_mismatches):\n",
    "    assert isinstance(filter_to_score, OrderedDict)\n",
    "    filter_matches = get_filter_matches(kmer_string=kmer_string, filter_strings=filter_to_score.keys(),\n",
    "                                        num_mismatches=num_mismatches)\n",
    "    total_score = 0\n",
    "    for a_filter in filter_matches:\n",
    "        total_score += filter_to_score[a_filter]\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that GATAAG scores pretty high for task 1 but not task 2, and CAGATG scores pretty high for task 2 but not task 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for GATAAG for task 1 and task 2:\n",
      "2.43825497038\n",
      "0.232850659289\n",
      "Scores for CAGATG for task 1 and task 2:\n",
      "0.405037627412\n",
      "2.02005926243\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "t1_filter_to_score = OrderedDict(zip(string_reps, t1_classifier.coef_[0]))\n",
    "t2_filter_to_score = OrderedDict(zip(string_reps, t2_classifier.coef_[0]))\n",
    "\n",
    "print(\"Scores for GATAAG for task 1 and task 2:\")\n",
    "print(get_total_kmer_score(kmer_string='GATAAG', filter_to_score=t1_filter_to_score, num_mismatches=num_mismatches))\n",
    "print(get_total_kmer_score(kmer_string='GATAAG', filter_to_score=t2_filter_to_score, num_mismatches=num_mismatches))\n",
    "print(\"Scores for CAGATG for task 1 and task 2:\")\n",
    "print(get_total_kmer_score(kmer_string='CAGATG', filter_to_score=t1_filter_to_score, num_mismatches=num_mismatches))\n",
    "print(get_total_kmer_score(kmer_string='CAGATG', filter_to_score=t2_filter_to_score, num_mismatches=num_mismatches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
